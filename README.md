# Speech-and-Emotion-Recognition-
Used LSTM and MFCC on RAVDESS dataset for emotion classification
ğŸ“ Recommended File Structure

speech-emotion-recognition-lstm-mfcc/
tensorflow
speech-emotion-recognition-lstm-mfcc/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (RAVDESS audio files)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (trained models will be saved here)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ (Jupyter notebooks for EDA and training)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


# Paths for data.
Ravdess = "/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/"

emotions
![image](https://github.com/user-attachments/assets/25b9fb6c-b1b6-4a0b-8f4f-ea4fbbb01a02)
![count for emotion graph](https://github.com/user-attachments/assets/4c34912d-a873-427a-b73f-3e0753a0b143)
